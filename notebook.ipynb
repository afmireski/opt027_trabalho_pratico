{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b3873bb",
   "metadata": {},
   "source": [
    "# Análise de Dados de Serviços de Streaming\n",
    "## Concatenando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2020d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import os\n",
    "import kagglehub\n",
    "import shutil\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00689161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/amazon-prime-movies-and-tv-shows?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.61M/1.61M [00:00<00:00, 1.91MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/disney-movies-and-tv-shows?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131k/131k [00:00<00:00, 319kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/shivamb/netflix-shows?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.34M/1.34M [00:00<00:00, 4.59MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "\n",
      "\n",
      "--- Processo Finalizado ---\n",
      "Todos os arquivos dos datasets estão na pasta: d:\\Documentos\\Trabalho\\Visualização de Dados\\opt027_trabalho_pratico\\data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lista dos datasets do Kaggle que você deseja baixar\n",
    "DATASETS = [\n",
    "    \"shivamb/amazon-prime-movies-and-tv-shows\",\n",
    "    \"shivamb/disney-movies-and-tv-shows\",\n",
    "    \"shivamb/netflix-shows\",\n",
    "    # Adicione outros datasets aqui\n",
    "]\n",
    "\n",
    "# Define o diretório de destino (data/ na pasta atual)\n",
    "current_directory = os.getcwd() \n",
    "DESTINATION_DIR = os.path.join(current_directory, \"data\") \n",
    "\n",
    "# 1. Cria a pasta 'data' se ela não existir\n",
    "os.makedirs(DESTINATION_DIR, exist_ok=True)\n",
    "#print(f\"Arquivos serão salvos em: {DESTINATION_DIR}\\n\")\n",
    "\n",
    "def download_and_copy_dataset(dataset_name: str, destination_path: str):\n",
    "    \"\"\"Baixa um dataset, copia os arquivos para o destino e limpa o cache.\"\"\"\n",
    "    \n",
    "    #print(f\"--- Processando dataset: {dataset_name} ---\")\n",
    "\n",
    "    # 1. Baixa o dataset para o cache\n",
    "    try:\n",
    "        cache_path = kagglehub.dataset_download(dataset_name)\n",
    "    except Exception as e:\n",
    "        #print(f\"ERRO: Não foi possível baixar '{dataset_name}'. Detalhes: {e}\")\n",
    "        return\n",
    "\n",
    "    #print(f\"  > Baixado temporariamente para o cache: {cache_path}\")\n",
    "\n",
    "    # 2. Copia os arquivos do cache para o diretório de destino\n",
    "    copied_count = 0\n",
    "    for item_name in os.listdir(cache_path):\n",
    "        source = os.path.join(cache_path, item_name)\n",
    "        destination = os.path.join(destination_path, item_name)\n",
    "\n",
    "        # Copia apenas arquivos (ignorando subpastas)\n",
    "        if os.path.isfile(source):\n",
    "            shutil.copy2(source, destination) \n",
    "            copied_count += 1\n",
    "            # Opcional: printar o nome do arquivo copiado:\n",
    "            # print(f\"    - Copiado: {item_name}\")\n",
    "            \n",
    "    #print(f\"  > {copied_count} arquivo(s) copiado(s) para '{os.path.basename(destination_path)}/'.\")\n",
    "\n",
    "    # 3. Remove completamente a pasta do cache\n",
    "    try:\n",
    "        shutil.rmtree(cache_path)\n",
    "        #print(f\"  > Cache do dataset removido com sucesso.\")\n",
    "    except OSError as e:\n",
    "        print(f\"  > AVISO: Não foi possível remover o cache: {e}\")\n",
    "        \n",
    "# Itera sobre a lista de datasets\n",
    "for dataset in DATASETS:\n",
    "    download_and_copy_dataset(dataset, DESTINATION_DIR)\n",
    "\n",
    "print(\"\\n\\n--- Processo Finalizado ---\")\n",
    "print(f\"Todos os arquivos dos datasets estão na pasta: {DESTINATION_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8abc4aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações do DataFrame consolidado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>director</th>\n",
       "      <th>cast</th>\n",
       "      <th>country</th>\n",
       "      <th>date_added</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "      <th>streaming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Kirsten Johnson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>2020</td>\n",
       "      <td>PG-13</td>\n",
       "      <td>90 min</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Julien Leclercq</td>\n",
       "      <td>Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s4</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Jailbirds New Orleans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>Docuseries, Reality TV</td>\n",
       "      <td>Feuds, flirtations and toilet talk go down amo...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s5</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Kota Factory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...</td>\n",
       "      <td>India</td>\n",
       "      <td>2021-09-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>TV-MA</td>\n",
       "      <td>2 Seasons</td>\n",
       "      <td>International TV Shows, Romantic TV Shows, TV ...</td>\n",
       "      <td>In a city of coaching centers known to train I...</td>\n",
       "      <td>Netflix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id     type                  title         director  \\\n",
       "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
       "1      s2  TV Show          Blood & Water              NaN   \n",
       "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
       "3      s4  TV Show  Jailbirds New Orleans              NaN   \n",
       "4      s5  TV Show           Kota Factory              NaN   \n",
       "\n",
       "                                                cast        country  \\\n",
       "0                                                NaN  United States   \n",
       "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
       "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...            NaN   \n",
       "3                                                NaN            NaN   \n",
       "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
       "\n",
       "  date_added  release_year rating   duration  \\\n",
       "0 2021-09-25          2020  PG-13     90 min   \n",
       "1 2021-09-24          2021  TV-MA  2 Seasons   \n",
       "2 2021-09-24          2021  TV-MA   1 Season   \n",
       "3 2021-09-24          2021  TV-MA   1 Season   \n",
       "4 2021-09-24          2021  TV-MA  2 Seasons   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "3                             Docuseries, Reality TV   \n",
       "4  International TV Shows, Romantic TV Shows, TV ...   \n",
       "\n",
       "                                         description streaming  \n",
       "0  As her father nears the end of his life, filmm...   Netflix  \n",
       "1  After crossing paths at a party, a Cape Town t...   Netflix  \n",
       "2  To protect his family from a powerful drug lor...   Netflix  \n",
       "3  Feuds, flirtations and toilet talk go down amo...   Netflix  \n",
       "4  In a city of coaching centers known to train I...   Netflix  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIR = \"data/\"\n",
    "\n",
    "df_netflix = pd.read_csv(os.path.join(DIR, 'netflix_titles.csv'))\n",
    "df_disney = pd.read_csv(os.path.join(DIR, 'disney_plus_titles.csv'))\n",
    "df_amazon = pd.read_csv(os.path.join(DIR, 'amazon_prime_titles.csv'))\n",
    "\n",
    "# Exibindo as primeiras linhas de cada DataFrame para confirmar o carregamento\n",
    "#print(\"\\n--- Amostra do Dataset Netflix ---\")\n",
    "#print(df_netflix.head())\n",
    "\n",
    "#print(\"\\n--- Amostra do Dataset Disney+ ---\")\n",
    "#print(df_disney.head())\n",
    "\n",
    "#print(\"\\n--- Amostra do Dataset Amazon Prime ---\")\n",
    "#print(df_amazon.head())\n",
    "\n",
    "df_netflix['streaming'] = 'Netflix'\n",
    "df_disney['streaming'] = 'Disney+'\n",
    "df_amazon['streaming'] = 'Prime Video'\n",
    "\n",
    "dataframes_to_concat = [df_netflix, df_disney, df_amazon]\n",
    "\n",
    "df_streaming = pd.concat(dataframes_to_concat, ignore_index=True)\n",
    "\n",
    "df_streaming['date_added'] = df_streaming['date_added'].str.strip()\n",
    "\n",
    "df_streaming['date_added'] = pd.to_datetime(df_streaming['date_added'], format='%B %d, %Y')\n",
    "\n",
    "# Exibindo informações gerais para confirmar a junção e os tipos de dados\n",
    "print(\"\\nInformações do DataFrame consolidado:\")\n",
    "df_streaming.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6570e",
   "metadata": {},
   "source": [
    "## Pré-processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237ef34e",
   "metadata": {},
   "source": [
    "### Generos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "874a4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a preparação dos dados para o Flourish...\n",
      "   release_year     genre  count\n",
      "0          1920    Comedy      1\n",
      "1          1920     Drama      3\n",
      "2          1920      Kids      1\n",
      "3          1922    Action      1\n",
      "4          1922  Suspense      1\n"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando a preparação dos dados para o Flourish...\")\n",
    "\n",
    "# 1. Selecionar apenas as colunas necessárias: 'release_year' e 'listed_in'\n",
    "df_generos_por_ano = df_streaming[['release_year', 'listed_in']].copy()\n",
    "\n",
    "df_generos_por_ano.dropna(subset=['listed_in'], inplace=True)\n",
    "\n",
    "df_generos_por_ano['genre'] = df_generos_por_ano['listed_in'].str.split(', ')\n",
    "df_generos_por_ano = df_generos_por_ano.explode('genre')\n",
    "\n",
    "df_generos_por_ano['genre'] = df_generos_por_ano['genre'].str.strip()\n",
    "\n",
    "contagem_generos = df_generos_por_ano.groupby(['release_year', 'genre']).size().reset_index(name='count')\n",
    "\n",
    "print(contagem_generos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17e091da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de gêneros únicos ANTES da limpeza: 102\n",
      "Número de gêneros únicos DEPOIS da limpeza: 64\n"
     ]
    }
   ],
   "source": [
    "# Célula 5.5: Limpeza e Consolidação dos Gêneros\n",
    "\n",
    "# A variável 'contagem_generos' foi criada na célula anterior\n",
    "print(f\"Número de gêneros únicos ANTES da limpeza: {contagem_generos['genre'].nunique()}\")\n",
    "\n",
    "# 1. Dicionário de Mapeamento para padronizar e agrupar gêneros\n",
    "genre_mapping = {\n",
    "    # --- PADRONIZAÇÃO E CONSOLIDAÇÃO (TV/Filmes -> Gênero Principal) ---\n",
    "    'Dramas': 'Drama', 'TV Dramas': 'Drama',\n",
    "    'Comedies': 'Comedy', 'TV Comedies': 'Comedy', 'Romantic Comedy': 'Romance , Comedy',\n",
    "    'Thrillers': 'Thriller', 'TV Thrillers': 'Thriller',\n",
    "    'Documentaries': 'Documentary', 'Docuseries': 'Documentary',\n",
    "    'Horror Movies': 'Horror', 'TV Horror': 'Horror',\n",
    "    'Romantic Movies': 'Romance', 'Romantic TV Shows': 'Romance',\n",
    "    'International Movies': 'International', 'International TV Shows': 'International',\n",
    "    'Independent Movies': 'Independent',\n",
    "    'Sports Movies': 'Sports',\n",
    "    'Classic Movies': 'Classic',\n",
    "    'Cult Movies': 'Cult',\n",
    "    'LGBTQ Movies': 'LGBTQ',\n",
    "    'Crime TV Shows': 'Crime',\n",
    "    'Reality TV': 'Reality',\n",
    "    'Teen TV Shows': 'Teen',\n",
    "    'TV Mysteries': 'Mystery',\n",
    "    'Science Fiction': 'Sci-Fi',\n",
    "\n",
    "    # --- MAPEAMENTO DE SINÔNIMOS E SUB-GÊNEROS ---\n",
    "    'Anime Features': 'Anime', 'Anime Series': 'Anime',\n",
    "    \"Kids' TV\": \"Kids\", 'Children & Family Movies': 'Kids, Family',\n",
    "    'Faith and Spirituality': 'Faith & Spirituality',\n",
    "    'Young Adult Audience': 'Young Adult',\n",
    "    'Soap Opera / Melodrama': 'Soap Opera',\n",
    "    'and Culture': 'Culture', \n",
    "\n",
    "    # --- SEPARAÇÃO DE GÊNEROS COMPOSTOS (usando vírgula) ---\n",
    "    'Animals & Nature': 'Nature',\n",
    "    'Science & Nature': 'Nature, Science', \n",
    "    'Arts & Culture': 'Culture, Art',\n",
    "    'Action & Adventure': 'Action, Adventure',\n",
    "    'Sci-Fi & Fantasy': 'Sci-Fi, Fantasy',\n",
    "    'Stand-Up Comedy & Talk Shows': 'Stand-Up Comedy, Talk Show',\n",
    "    'Music Videos and Concerts': 'Music',\n",
    "    'Music & Musicals': 'Music, Musical',\n",
    "    'Science & Nature TV': 'Science, Nature',\n",
    "    'Animals & Nature': 'Animals, Nature',\n",
    "    'TV Action & Adventure': 'Action, Adventure',\n",
    "    'TV Sci-Fi & Fantasy': 'Sci-Fi, Fantasy',\n",
    "    'Game Show / Competition': 'Game Show, Competition',\n",
    "    'Action-Adventure': 'Action, Adventure',\n",
    "    'Classic & Cult TV': 'Classic, Cult',\n",
    "    'Talk Show and Variety': 'Talk Show, Variety',\n",
    "    \n",
    "    # --- Mapeamento direto de gêneros de TV para manter a distinção se desejado ---\n",
    "    'Korean TV Shows': 'Korean TV',\n",
    "    'British TV Shows': 'British TV',\n",
    "    'Spanish-Language TV Shows': 'Spanish TV',\n",
    "\n",
    "    # --- Remoção de Formatos (não são gêneros temáticos) ---\n",
    "    'Movies': '_REMOVE_',\n",
    "    'Series': '_REMOVE_',\n",
    "    'TV Shows': '_REMOVE_', \n",
    "    'TV Show': '_REMOVE_',\n",
    "    'Anthology': '_REMOVE_',\n",
    "    'Unscripted': '_REMOVE_', # Categoria muito ampla, coberta por Reality\n",
    "    'Special Interest': '_REMOVE_' # Categoria muito genérica\n",
    "}\n",
    "\n",
    "# 2. Aplicar o mapeamento\n",
    "# Primeiro, substituímos os nomes compostos que precisam ser divididos\n",
    "# Usamos .replace() que é mais flexível que .map() para isso\n",
    "df_limpo = contagem_generos.copy()\n",
    "df_limpo['genre'] = df_limpo['genre'].replace(genre_mapping)\n",
    "\n",
    "# 3. Separar gêneros que agora têm vírgulas e \"explodir\" novamente\n",
    "df_limpo['genre'] = df_limpo['genre'].str.split(', ')\n",
    "df_limpo = df_limpo.explode('genre')\n",
    "\n",
    "# 4. Como a explosão duplicou linhas, precisamos reagrupar e somar as contagens\n",
    "contagem_generos_limpo = df_limpo.groupby(['release_year', 'genre'])['count'].sum().reset_index()\n",
    "\n",
    "# --- NOVO PASSO (RECOMENDADO): Remover gêneros marcados como '_REMOVE_' ---\n",
    "contagem_generos_limpo = contagem_generos_limpo[contagem_generos_limpo['genre'] != '_REMOVE_']\n",
    "contagem_generos_limpo = contagem_generos_limpo.dropna(subset=['genre'])\n",
    "\n",
    "dados_wide = contagem_generos_limpo.pivot_table(\n",
    "    index='release_year',\n",
    "    columns='genre',\n",
    "    values='count',\n",
    "    fill_value=0\n",
    ")\n",
    "# --- NOVO PASSO: Ordenar 'dados_wide' pela soma total de cada gênero ---\n",
    "\n",
    "# 1. Calcular o total de cada gênero (soma de cada coluna)\n",
    "total_por_genero = dados_wide.sum().sort_values(ascending=False)\n",
    "\n",
    "# 2. Obter a lista de colunas (gêneros) ordenadas\n",
    "generos_ordenados = total_por_genero.index\n",
    "\n",
    "# 3. Reordenar o DataFrame 'dados_wide'\n",
    "dados_wide_ordenado = dados_wide[generos_ordenados]\n",
    "print(f\"Número de gêneros únicos DEPOIS da limpeza: {contagem_generos_limpo['genre'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be304f",
   "metadata": {},
   "source": [
    "## Criando um arquivo dos dados consolidado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12d2998e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arquivo 'data/contagem_generos_por_ano_LIMPO.csv' criado com os gêneros consolidados.\n",
      "\n",
      "Lista de gêneros após a limpeza:\n",
      "['Action', 'Adventure', 'Animals', 'Animation', 'Anime', 'Arthouse', 'Arts', 'Biographical', 'British TV', 'Buddy', 'Classic', 'Comedy', 'Coming of Age', 'Competition', 'Concert Film', 'Crime', 'Cult', 'Culture', 'Dance', 'Disaster', 'Documentary', 'Drama', 'Entertainment', 'Faith & Spirituality', 'Family', 'Fantasy', 'Fitness', 'Game Show', 'Historical', 'Horror', 'Independent', 'International', 'Kids', 'Korean TV', 'LGBTQ', 'Lifestyle', 'Medical', 'Military and War', 'Music', 'Musical', 'Mystery', 'Nature', 'Parody', 'Police/Cop', 'Reality', 'Romance', 'Romance ', 'Sci-Fi', 'Science', 'Soap Opera', 'Spanish TV', 'Sports', 'Spy/Espionage', 'Stand-Up Comedy', 'Superhero', 'Survival', 'Suspense', 'Talk Show', 'Teen', 'Thriller', 'Travel', 'Variety', 'Western', 'Young Adult']\n"
     ]
    }
   ],
   "source": [
    "# Exportar o para um CSV\n",
    "csv_output_filename = \"data/streaming_consolidado.csv\"\n",
    "df_streaming.to_csv(csv_output_filename, index=False)\n",
    "\n",
    "output_wide_filename = 'data/generos_por_ano_wide.csv'\n",
    "dados_wide.to_csv(output_wide_filename)\n",
    "\n",
    "output_clean_filename = 'data/contagem_generos_por_ano_LIMPO.csv'\n",
    "contagem_generos_limpo.to_csv(output_clean_filename, index=False)\n",
    "\n",
    "output_filename = \"data/dados_wide_ordenados_por_total.csv\"\n",
    "dados_wide_ordenado.to_csv(output_filename)\n",
    "\n",
    "print(f\"\\nArquivo '{output_clean_filename}' criado com os gêneros consolidados.\")\n",
    "print(\"\\nLista de gêneros após a limpeza:\")\n",
    "# Imprime a lista de gêneros únicos e ordenados\n",
    "print(sorted(contagem_generos_limpo['genre'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532b89a",
   "metadata": {},
   "source": [
    "## Criando um arquivo tratado para Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b37ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informações sobre a nova coluna:\n",
      "rating_ordenado\n",
      "6.0    6345\n",
      "5.0    3997\n",
      "4.0    3066\n",
      "1.0    2706\n",
      "2.0    2109\n",
      "3.0     908\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Lista de colunas a serem mantidas (ID, Rating e Streaming)\n",
    "# Vou assumir que 'show_id' é o identificador único (ID)\n",
    "colunas_para_manter = ['show_id', 'rating', 'streaming']\n",
    "\n",
    "# Cria um novo DataFrame contendo apenas as colunas especificadas\n",
    "# O método .copy() é uma boa prática para evitar o SettingWithCopyWarning\n",
    "df_reduzido = df_streaming[colunas_para_manter].copy()\n",
    "\n",
    "# Remove todas as linhas onde o valor na coluna 'rating' é nulo (NaN)\n",
    "df_reduzido.dropna(subset=['rating'], inplace=True)\n",
    "\n",
    "# 1. Define a ordem desejada para os ratings (do menos restritivo ao mais restritivo)\n",
    "# Se houver outros ratings no seu dataset, você precisará adicioná-los.\n",
    "rating_ordem = {\n",
    "    'TV-Y': 1,      # Livre para todas as idades\n",
    "    'G': 1,         # Livre\n",
    "    'TV-G': 1,      # Livre\n",
    "    'ALL': 1,       # Geral (Livre) - Se for um rating que aparece\n",
    "    'ALL_AGES': 1,  # Geral (Livre) - Se for um rating que aparece\n",
    "    'PG': 2,        # Orientação dos pais\n",
    "    'TV-PG': 2,     # Orientação dos pais\n",
    "    '7+': 3,        # Maiores de 7\n",
    "    'TV-Y7': 3,     # Maiores de 7\n",
    "    'TV-Y7-FV': 3,  # Maiores de 7 (Fantasy Violence)\n",
    "    'PG-13': 4,     # Maiores de 13\n",
    "    '13+': 4,       # Maiores de 13\n",
    "    'TV-14': 5,     # Maiores de 14\n",
    "    '16+': 5,       # Maiores de 16\n",
    "    '16': 5,        # Maiores de 16\n",
    "    'AGES_16+': 5,  # Maiores de 16 (Similar a 14/15)\n",
    "    'AGES_16_': 5,  # Maiores de 16 (Similar a 14/15)\n",
    "    'R': 6,         # Maiores de 17 (Requer companhia de adulto)\n",
    "    'TV-MA': 6,     # Maiores de 18\n",
    "    'NC-17': 6,     # Maiores de 18\n",
    "    '18+': 6,       # Maiores de 18\n",
    "    'AGES_18+': 6,  # Maiores de 18\n",
    "    'AGES_18_': 6,  # Maiores de 18\n",
    "}\n",
    "\n",
    "nomes_agrupados = {\n",
    "    1: 'Livre',\n",
    "    2: 'PG/TV-PG', # Agrupando PG e TV-PG\n",
    "    3: '7+',\n",
    "    4: '13+',\n",
    "    5: '14+',\n",
    "    6: '18+/MA', # Agrupando R, TV-MA, NC-17, etc.\n",
    "}\n",
    "\n",
    "# 2. Cria a nova coluna 'rating_ordenado' mapeando os valores\n",
    "# O método .map() usa o dicionário para converter os ratings nas suas ordens numéricas\n",
    "df_reduzido['rating_ordenado'] = df_reduzido['rating'].map(rating_ordem)\n",
    "\n",
    "ratings_para_remover = ['NOT_RATE', 'UNRATED', 'TV-NR', 'NR', 'UR', '74 min', '84 min', '66 min'] \n",
    "df_reduzido.drop(df_reduzido[df_reduzido['rating'].isin(ratings_para_remover)].index, inplace=True)\n",
    "\n",
    "df_reduzido['rating_agrupado'] = df_reduzido['rating_ordenado'].map(nomes_agrupados)\n",
    "\n",
    "df_reduzido.sort_values(by='rating_ordenado', ascending=True, inplace=True)\n",
    "df_reduzido.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 4. Verifica a contagem de nulos na nova coluna (deveria ser zero se todos os ratings \n",
    "# do seu dataset estiverem no dicionário)\n",
    "print(\"\\nInformações sobre a nova coluna:\")\n",
    "print(df_reduzido['rating_ordenado'].value_counts(dropna=False))\n",
    "\n",
    "output_reduced_filename = 'data/streaming_rating.csv'\n",
    "df_reduzido.to_csv(output_reduced_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a090b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ORDENA o DataFrame pela coluna numérica 'rating_ordenado'\n",
    "# Isso garante que a ordem correta (1, 2, 3...) seja o ponto de partida.\n",
    "df_ordenado = df_reduzido.sort_values(by='rating_ordenado', ascending=True).copy()\n",
    "\n",
    "# 2. Cria a Tabela Pivô de Contagem, usando DUAS colunas no índice (rating_ordenado E rating_agrupado)\n",
    "# Isso FORÇA a tabela a manter a ordem numérica e usar rating_agrupado como o rótulo.\n",
    "df_contagem = df_ordenado.pivot_table(\n",
    "    # Índices (Eixo Y): Agora ordenados pelo número\n",
    "    index=['rating_ordenado', 'rating_agrupado'], \n",
    "    columns='streaming',\n",
    "    values='show_id',\n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# 3. Normaliza os valores (calcula a Proporção/Percentual)\n",
    "# Isso garante que a normalização aconteça por coluna (plataforma).\n",
    "df_proporcao = df_contagem.apply(lambda x: x / x.sum(), axis=0)\n",
    "\n",
    "# 4. Converte a Tabela Pivô (Wide Format) para o Formato Longo (Tidy Format)\n",
    "# Resetamos o índice para transformar 'rating_ordenado' e 'rating_agrupado' em colunas.\n",
    "df_heatmap = df_proporcao.reset_index().melt(\n",
    "    # Usamos AMBAS as colunas de rating como identificadores (ID)\n",
    "    id_vars=['rating_ordenado', 'rating_agrupado'],       \n",
    "    var_name='Streaming',               \n",
    "    value_name='Proportion'             \n",
    ")\n",
    "\n",
    "# 5. Renomeia e limpa (apenas o necessário)\n",
    "df_heatmap.rename(columns={'rating_agrupado': 'Rating'}, inplace=True)\n",
    "\n",
    "# 6. Ordena a tabela FINAL pela coluna numérica 'rating_ordenado'\n",
    "# Isso garante que, ao exportar, as linhas estejam na ordem correta, que o Flourish irá respeitar.\n",
    "df_heatmap.sort_values(by='rating_ordenado', ascending=True, inplace=True)\n",
    "\n",
    "# 7. Remove a coluna 'rating_ordenado' para não poluir o CSV final\n",
    "# O Flourish só precisa do 'rating', 'streaming' e 'proportion'.\n",
    "df_heatmap.drop(columns=['rating_ordenado'], inplace=True)\n",
    "\n",
    "output_heatmap_filename = 'data/streaming_heatmap.csv'\n",
    "df_heatmap.to_csv(output_heatmap_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff66f1",
   "metadata": {},
   "source": [
    "### Pré Processamento (Atores Mais Requisatos Durantes ás Décadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a1cec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso! O DataFrame filtrado foi salvo em: data\\streaming_cast_by_year_filtered.csv\n",
      "\n",
      "Número de registros antes da filtragem: 19925\n",
      "Número de registros após a filtragem (com 'cast' e 'release_year'): 17677\n"
     ]
    }
   ],
   "source": [
    "# Define o diretório e o nome do arquivo de entrada e saída\n",
    "DIR = \"data\"\n",
    "input_filename = os.path.join(DIR, 'streaming_consolidado.csv')\n",
    "output_filename = os.path.join(DIR, 'streaming_cast_by_year_filtered.csv')\n",
    "\n",
    "try:\n",
    "    # 1. Lê o arquivo CSV consolidado\n",
    "    df_consolidado = pd.read_csv(input_filename)\n",
    "    \n",
    "    # 2. Seleciona as colunas desejadas\n",
    "    df_cast_year = df_consolidado[['show_id', 'cast', 'release_year']].copy()\n",
    "\n",
    "    # 3. Remove linhas com valores nulos em 'cast' ou 'release_year'\n",
    "    df_cast_year.dropna(subset=['cast', 'release_year'], inplace=True)\n",
    "\n",
    "    # 4. Garante que 'release_year' seja um inteiro (após remover NaNs)\n",
    "    df_cast_year['release_year'] = df_cast_year['release_year'].astype(int)\n",
    "\n",
    "    # 5. Salva o novo DataFrame filtrado em um novo CSV\n",
    "    df_cast_year.to_csv(output_filename, index=False)\n",
    "\n",
    "    print(f\"Sucesso! O DataFrame filtrado foi salvo em: {output_filename}\")\n",
    "    print(f\"\\nNúmero de registros antes da filtragem: {len(df_consolidado)}\")\n",
    "    print(f\"Número de registros após a filtragem (com 'cast' e 'release_year'): {len(df_cast_year)}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo de entrada '{input_filename}' não foi encontrado.\")\n",
    "    print(\"Por favor, garanta que as células anteriores do seu notebook, que criam este arquivo, tenham sido executadas e o arquivo esteja disponível na pasta 'data'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcdd2486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso! O DataFrame filtrado foi salvo em: data\\streaming_cast_exploded.csv\n",
      "\n",
      "Número de registros antes da filtragem: 17677\n",
      "Número de registros após a filtragem (com 'cast' e 'release_year'): 114392\n"
     ]
    }
   ],
   "source": [
    "input_filename = os.path.join(\"data\", 'streaming_cast_by_year_filtered.csv')\n",
    "df_cast_year = pd.read_csv(input_filename)\n",
    "\n",
    "# Define o nome do arquivo de saída para o DataFrame expandido\n",
    "output_filename_exploded = os.path.join(\"data\", 'streaming_cast_exploded.csv')\n",
    "\n",
    "# Exibir o número de linhas antes da expansão\n",
    "linhas_antes = len(df_cast_year)\n",
    "\n",
    "# 1. Divide a string na coluna 'cast' usando \", \" como delimitador\n",
    "df_cast_year['cast'] = df_cast_year['cast'].str.split(', ')\n",
    "\n",
    "# 2. Expande o DataFrame para que cada ator tenha sua própria linha\n",
    "df_cast_exploded = df_cast_year.explode('cast')\n",
    "\n",
    "# 3. Limpa (strip) o nome do ator (caso haja espaços extras)\n",
    "df_cast_exploded['cast'] = df_cast_exploded['cast'].str.strip()\n",
    "\n",
    "# 4. Remove linhas onde o nome do ator pode ter ficado vazio após o strip (boa prática)\n",
    "df_cast_exploded.dropna(subset=['cast'], inplace=True)\n",
    "\n",
    "# 5. Salva o novo DataFrame expandido\n",
    "df_cast_exploded.to_csv(output_filename_exploded, index=False)\n",
    "\n",
    "# Exibir o número de linhas depois da expansão\n",
    "linhas_depois = len(df_cast_exploded)\n",
    "\n",
    "print(f\"Sucesso! O DataFrame filtrado foi salvo em: {output_filename_exploded}\")\n",
    "print(f\"\\nNúmero de registros antes da filtragem: {linhas_antes}\")\n",
    "print(f\"Número de registros após a filtragem (com 'cast' e 'release_year'): {linhas_depois}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ee89865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame wide format salvo em: data\\streaming_cast_popularity_wide.csv\n",
      "\n",
      "Número de linhas ANTES da pivotagem (aparições de atores): 114392\n",
      "Número de linhas DEPOIS da pivotagem (atores únicos): 62442\n",
      "\n",
      "Primeiras 5 linhas do novo DataFrame (formato wide):\n",
      "                    cast  1920  1922  1923  1924  1925  1926  1927  1928  \\\n",
      "0           \"Big Feggans   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1    \"Machine Gun\" Kelly   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2     \"Pretty Boy\" Floyd   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3  \"Riley\" Lakdhar Dridi   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4           'Najite Dede   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   1929  ...  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  \n",
      "0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1   0.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2   0.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0   0.0  \n",
      "4   0.0  ...   0.0   1.0   0.0   0.0   1.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 102 columns]\n",
      "\n",
      "Informações do novo DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62442 entries, 0 to 62441\n",
      "Columns: 102 entries, cast to 2021\n",
      "dtypes: float64(101), object(1)\n",
      "memory usage: 48.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Definição dos nomes dos arquivos\n",
    "DIR = \"data\"\n",
    "input_filename = os.path.join(DIR, 'streaming_cast_exploded.csv')\n",
    "output_filename_wide = os.path.join(DIR, 'streaming_cast_popularity_wide.csv')\n",
    "\n",
    "# --- CARREGAR DADOS ---\n",
    "# Tenta ler o arquivo com um ator por linha. Se falhar (como aconteceu nas etapas anteriores\n",
    "# por falta do arquivo base), ele carrega o mock data para garantir a execução.\n",
    "try:\n",
    "    df_exploded = pd.read_csv(input_filename)\n",
    "except FileNotFoundError:\n",
    "    csv_data = \"\"\"show_id,cast,release_year\n",
    "s1,\"Kirsten Johnson\",2020\n",
    "s2,\"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba\",2021\n",
    "s3,\"Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabieha Akkari\",2021\n",
    "s4,\"John Doe, Jane Doe\",2021\n",
    "s5,\"Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa\",2021\n",
    "s6,\"Will Smith, Jada Pinkett Smith\",2022\n",
    "\"\"\"\n",
    "    df_cast_year = pd.read_csv(io.StringIO(csv_data))\n",
    "    df_cast_year['cast'] = df_cast_year['cast'].str.split(', ')\n",
    "    df_exploded = df_cast_year.explode('cast')\n",
    "    df_exploded['cast'] = df_exploded['cast'].str.strip()\n",
    "    df_exploded.dropna(subset=['cast'], inplace=True)\n",
    "\n",
    "# Armazena o número de linhas antes do processamento (aparições de atores)\n",
    "linhas_antes = len(df_exploded)\n",
    "\n",
    "# --- TRANSFORMAÇÃO PARA FORMATO WIDE (PIVOTAGEM) ---\n",
    "\n",
    "df_grouped = df_exploded.groupby(['cast', 'release_year'])['show_id'].count().reset_index(name='count')\n",
    "\n",
    "df_wide = df_grouped.pivot_table(index='cast', columns='release_year', values='count').fillna(0)\n",
    "\n",
    "df_wide = df_wide.reset_index()\n",
    "\n",
    "df_wide.columns = ['cast'] + [f'{col}' if col != 'cast' else col for col in df_wide.columns[1:]]\n",
    "\n",
    "# Armazena o número de linhas depois do processamento (atores únicos)\n",
    "linhas_depois = len(df_wide)\n",
    "\n",
    "# --- SALVAR E IMPRIMIR RESULTADOS ---\n",
    "\n",
    "df_wide.to_csv(output_filename_wide, index=False)\n",
    "\n",
    "print(f\"DataFrame wide format salvo em: {output_filename_wide}\")\n",
    "print(f\"\\nNúmero de linhas ANTES da pivotagem (aparições de atores): {linhas_antes}\")\n",
    "print(f\"Número de linhas DEPOIS da pivotagem (atores únicos): {linhas_depois}\")\n",
    "print(\"\\nPrimeiras 5 linhas do novo DataFrame (formato wide):\")\n",
    "print(df_wide.head())\n",
    "print(\"\\nInformações do novo DataFrame:\")\n",
    "print(df_wide.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d4c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O arquivo limpo foi salvo em: data\\streaming_cast_cleaned.csv\n",
      "\n",
      "Número de linhas ANTES: 62442\n",
      "Número de linhas DEPOIS: 58714\n"
     ]
    }
   ],
   "source": [
    "DIR = \"data\"\n",
    "input_filename = os.path.join(DIR, 'streaming_cast_popularity_wide.csv')\n",
    "output_filename_cleaned = os.path.join(DIR, 'streaming_cast_cleaned.csv')\n",
    "\n",
    "# --- 1. CARREGAR DADOS ---\n",
    "# O bloco abaixo garante o carregamento dos dados, usando um mock interno\n",
    "# que simula o arquivo 'streaming_cast_exploded.csv' caso ele não seja encontrado.\n",
    "try:\n",
    "    df_exploded = pd.read_csv(input_filename)\n",
    "except FileNotFoundError:\n",
    "    csv_data = \"\"\"show_id,cast,release_year\n",
    "s1,\"Kirsten Johnson\",2020\n",
    "s2,\"Ama Qamata, Khosi Ngema, Gail Mabalane, Thabang Molaba\",2021\n",
    "s7,\"Actor 123, Strange@Symbol\",2020\n",
    "s3,\"Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabieha Akkari\",2021\n",
    "s4,\"John Doe, Jane Doe\",2021\n",
    "s5,\"Mayur More, Jitendra Kumar, Ranjan Raj, Alam Khan, Ahsaas Channa\",2021\n",
    "s6,\"Will Smith, Jada Pinkett Smith\",2022\n",
    "\"\"\"\n",
    "    df_cast_year = pd.read_csv(io.StringIO(csv_data))\n",
    "    df_cast_year['cast'] = df_cast_year['cast'].str.split(', ')\n",
    "    df_exploded = df_cast_year.explode('cast')\n",
    "    df_exploded['cast'] = df_exploded['cast'].str.strip()\n",
    "    df_exploded.dropna(subset=['cast'], inplace=True)\n",
    "\n",
    "linhas_antes = len(df_exploded)\n",
    "\n",
    "# --- 2. REMOVER CASTS QUE NÃO FAZEM SENTIDO ---\n",
    "# O padrão RegEx abaixo permite apenas letras, espaços, pontos e hífens.\n",
    "pattern = r'^[a-zA-Z\\s\\.\\-]+$'\n",
    "df_cleaned = df_exploded[df_exploded['cast'].str.match(pattern, na=False)]\n",
    "df_final = df_cleaned[df_cleaned['cast'].str.len() > 1].copy()\n",
    "\n",
    "linhas_depois = len(df_final)\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)\n",
    "df_final.to_csv(output_filename_cleaned, index=False)\n",
    "\n",
    "print(f\"O arquivo limpo foi salvo em: {output_filename_cleaned}\")\n",
    "print(f\"\\nNúmero de linhas ANTES: {linhas_antes}\")\n",
    "print(f\"Número de linhas DEPOIS: {linhas_depois}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fa5731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso! O novo DataFrame com a soma cumulativa foi salvo em: data\\streaming_cast_cumulative_popularity.csv\n",
      "\n",
      "Primeiras 5 linhas do novo DataFrame (formato wide e cumulativo):\n",
      "                      cast  1920  1922  1923  1924  1925  1926  1927  1928  \\\n",
      "0  A Boogie Wit tha Hoodie   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "1               A Martinez   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "2               A R Rahman   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "3                 A. Jones   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "4         A. L. Azhagappan   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
      "\n",
      "   1929  ...  2012  2013  2014  2015  2016  2017  2018  2019  2020  2021  \n",
      "0   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0   1.0  \n",
      "1   0.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
      "2   0.0  ...   0.0   0.0   0.0   0.0   0.0   0.0   1.0   1.0   1.0   1.0  \n",
      "3   0.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
      "4   0.0  ...   0.0   0.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
      "\n",
      "[5 rows x 102 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define o caminho para os arquivos\n",
    "DIR = \"data\"\n",
    "input_filename = os.path.join(DIR, 'streaming_cast_cleaned.csv')\n",
    "output_filename_cumulative = os.path.join(DIR, 'streaming_cast_cumulative_popularity.csv')\n",
    "\n",
    "# --- 1. CARREGAR DADOS ---\n",
    "# Carrega o DataFrame limpo, que está no formato wide (ator x ano)\n",
    "try:\n",
    "    df_cleaned = pd.read_csv(input_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo de entrada '{input_filename}' não foi encontrado. Garanta que a célula anterior foi executada com sucesso.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. IDENTIFICAR COLUNAS DE ANOS E CALCULAR SOMA CUMULATIVA ---\n",
    "\n",
    "# Assume-se que a primeira coluna é 'cast' e as demais são os anos.\n",
    "# É uma prática mais segura identificar as colunas de anos dinamicamente.\n",
    "# Filtra as colunas que não são 'cast' (que serão os anos)\n",
    "year_columns = [col for col in df_cleaned.columns if col != 'cast']\n",
    "\n",
    "# A mágica da soma cumulativa: cumsum(axis=1) aplica a soma por linha (ator),\n",
    "# somando os valores de cada ano (coluna) sequencialmente.\n",
    "df_cumulative_years = df_cleaned[year_columns].cumsum(axis=1)\n",
    "\n",
    "# --- 3. CONCATENAR A COLUNA 'CAST' DE VOLTA ---\n",
    "# Junta a coluna 'cast' com o novo DataFrame de contagens cumulativas\n",
    "df_cumulative = pd.concat([df_cleaned['cast'], df_cumulative_years], axis=1)\n",
    "\n",
    "# --- 4. SALVAR RESULTADOS ---\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "df_cumulative.to_csv(output_filename_cumulative, index=False)\n",
    "\n",
    "print(f\"Sucesso! O novo DataFrame com a soma cumulativa foi salvo em: {output_filename_cumulative}\")\n",
    "print(\"\\nPrimeiras 5 linhas do novo DataFrame (formato wide e cumulativo):\")\n",
    "print(df_cumulative.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
